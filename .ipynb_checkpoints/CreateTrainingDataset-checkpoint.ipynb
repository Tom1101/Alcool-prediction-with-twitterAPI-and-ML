{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><h4>Get Dataset + exctrating training and testing data</h4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total tweets(100%):\t\t\t88276\n",
      "Total tweets for nlp(80%):\t\t70621\n",
      "Total tweets for nlp training(64%):\t56497\n",
      "Total tweets for nlp testing(16%):\t14124\n"
     ]
    }
   ],
   "source": [
    "dataset_file = './Dataset/Alcool/tweets.txt'\n",
    "\n",
    "dataset = []\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "# All tweets\n",
    "with open(dataset_file) as f:\n",
    "    for line in f:\n",
    "        dataset.append(json.loads(line))\n",
    "        \n",
    "# Dataframe all tweets       \n",
    "df_tweets = pd.DataFrame(dataset)\n",
    "# Filter lang = 'En' only\n",
    "df_tweets = df_tweets.loc[(df_tweets['lang'].str.contains(\"en\", na=False))]\n",
    "df_tweets.reset_index(drop=True, inplace=True)\n",
    "\n",
    "length = len(df_tweets)\n",
    "length_80per = int(round(length*80/100, 0))\n",
    "length_64per = int(round(length*64/100, 0))\n",
    "length_16per = int(round(length*16/100, 0))\n",
    "print(f'\\nTotal tweets(100%):\\t\\t\\t{length}\\nTotal tweets for nlp(80%):\\t\\t{length_80per}\\nTotal tweets for nlp training(64%):\\t{length_64per}\\nTotal tweets for nlp testing(16%):\\t{length_16per}')  \n",
    "\n",
    "# Train dataset -> dataframe -> data text\n",
    "for tweet in df_tweets['text'].head(length_64per):\n",
    "    train_dataset.append(tweet)\n",
    "df_tweets_train = pd.DataFrame(train_dataset, columns={'text'})\n",
    "train_texts = df_tweets_train['text']\n",
    "\n",
    "# Test dataset-> dataframe -> data text\n",
    "for tweet in df_tweets['text'].tail(length_16per):\n",
    "    test_dataset.append(tweet)\n",
    "df_tweets_test = pd.DataFrame(test_dataset, columns={'text'})\n",
    "test_texts = df_tweets_test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><h4> Label processing for training data</h4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryTextBlob(tweets):\n",
    "    labels = []\n",
    "    for tweet in tweets:\n",
    "        analysis = TextBlob(tweet)\n",
    "        polarity1 = round(analysis.sentiment.polarity, 2)\n",
    "        if(polarity1 > 0.0):# positive feeling\n",
    "            polarity2 = 1\n",
    "            labels.append(polarity2)\n",
    "        elif(polarity1 < 0.0):# negative feeling\n",
    "            polarity2 = -1\n",
    "            labels.append(polarity2)\n",
    "        else:# neutral feeling\n",
    "            polarity2 = 0\n",
    "            labels.append(polarity2)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = binaryTextBlob(train_texts)\n",
    "test_labels = binaryTextBlob(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><h4> Training and Testing tweets formatting</h4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeTextLabel(tweets_texts,tweets_labels):\n",
    "    tweets = []\n",
    "    for i in range(0, len(tweets_labels)): \n",
    "        labeled_tweet = []\n",
    "        label = tweets_labels[i]\n",
    "        tweet = tweets_texts[i]\n",
    "        labeled_tweet.append(label)\n",
    "        labeled_tweet.append(tweet)\n",
    "        tweets.append(labeled_tweet)\n",
    "    return tweets\n",
    "\n",
    "def textAlone(tweets_text):\n",
    "    tweets = []\n",
    "    for i in range(0, len(tweets_text)): \n",
    "        tweet = tweets_text[i]\n",
    "        tweets.append(tweet)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = mergeTextLabel(train_texts, train_labels)\n",
    "#test_tweets = textAlone(test_texts)\n",
    "test_tweets = mergeTextLabel(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><h4>CSV Export</h4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflistFinalTrain = pd.DataFrame(train_tweets, columns = ['label', 'tweet'])\n",
    "#dflistFinalTest = pd.DataFrame(test_tweets, columns = ['text'])\n",
    "dflistFinalTest = pd.DataFrame(test_tweets, columns = ['label', 'tweet'])\n",
    "\n",
    "dfTrain = pd.DataFrame(dflistFinalTrain)\n",
    "dfTrain.to_csv('./Dataset/Alcool/train_tweets_dataset.csv', index=False)\n",
    "dfTest = pd.DataFrame(dflistFinalTest)\n",
    "dfTest.to_csv('./Dataset/Alcool/test_tweets_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
